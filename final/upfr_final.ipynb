{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "eb5b7d66-b50e-417c-b08c-f77b1ebd5dc3",
   "metadata": {},
   "source": [
    "Using Python for Research\n",
    "Final\n",
    "\n",
    "Jason Padgett\n",
    "10/06/2024\n",
    "\n",
    "Given the project of predicting movement data from a 'count your steps' app, using another data set with the movements defined.\n",
    "\n",
    "During the class, I was able to use the tools presented to find homework answers, but felt that I didn't yet understand what those tools were doing in the background, and what some of the returned numbers were representing. So, my first attempt at this project was using brute force. I wanted to avoid using the tools, do the math myself, and teach myself where those numbers were coming from. I completed working code, but the results, when plugged into the test form, only rated an accuracy of about 26%, which is no better than random chance. So, run number 1 was scrapped.\n",
    "\n",
    "Final v.2 was attempted using LogisticRegression and RandomForestClassifier. I used some plotting code from class 5-2 to render a comparison of the accuracy of each tool and found that RandomForestClassifier was yielding better accuracy. So, with a clean sheet of paper, I wrote new code based on using RandomForestClassifier.\n",
    "\n",
    "Initializing the code, I state my imports, set the location of the data I am going to use, start my timer, and grab the training and test data from external files:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "361f13d8-be43-4f4a-af87-ba44dffbdcb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import RandomizedSearchCV, cross_val_score\n",
    "from scipy.stats import randint\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "data_dir = \"./data\"\n",
    "\n",
    "# start process timer\n",
    "start_time = datetime.datetime.now()\n",
    "\n",
    "# Load data from files - training data\n",
    "df_train_time_series = pd.read_csv(os.path.join(data_dir, \"train_time_series.csv\"))\n",
    "df_train_labels = pd.read_csv(os.path.join(data_dir, \"train_labels.csv\"))\n",
    "\n",
    "# Load data from files - test data\n",
    "df_test_time_series = pd.read_csv(os.path.join(data_dir, \"test_time_series.csv\"))\n",
    "df_test_labels = pd.read_csv(os.path.join(data_dir, \"test_labels_input.csv\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c299dd76-0501-4f7c-a0ed-429a706d1ee9",
   "metadata": {},
   "source": [
    "Having grabbed the data, I want to set that data up in tables which will give me easier access during the classification process:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9e3d905b-7884-499b-810c-69d29ffa5821",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_table(table_l, table_ts):\n",
    "    \"\"\"Formatting data collected from external files, and forming a new table with the data I will use during the training / prediction process\"\"\"\n",
    "    table = []\n",
    "    for i in range(len(table_l)):\n",
    "        for j in range(len(table_ts)):\n",
    "            if table_l.timestamp.iloc[i] == table_ts.timestamp.iloc[j]:\n",
    "                table.append([\n",
    "                    table_ts.x.iloc[j],\n",
    "                    table_ts.y.iloc[j],\n",
    "                    table_ts.z.iloc[j],\n",
    "                    table_l.label.iloc[i]\n",
    "                ])\n",
    "    return table\n",
    "\n",
    "\n",
    "train_table = pd.DataFrame(set_table(df_train_labels, df_train_time_series), columns=['x', 'y', 'z', 'label'])\n",
    "test_table = pd.DataFrame(set_table(df_test_labels, df_test_time_series), columns=['x', 'y', 'z', 'label'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "237c97c3-6999-4077-81dd-06b1e40369d9",
   "metadata": {},
   "source": [
    "Using the tables created, next I set up the variables I will use:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "29ac165a-1251-4723-85ae-9660c1dcaa00",
   "metadata": {},
   "outputs": [],
   "source": [
    "classification_target = 'label'\n",
    "all_covariates = ['x', 'y', 'z']\n",
    "\n",
    "X, y = train_table[all_covariates], train_table[classification_target]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "965de071-4a6a-471c-aec9-0d4a26e3e89f",
   "metadata": {},
   "source": [
    "The classification porcess:\n",
    "I struggled trying to get results with any kind of decent accuracy, so I started researching. I found RandomizedSearchCV which creates mutiple RandomForestClassifiers, checks the accuracy of each tree, and makes predictions based on the most accurate tree. This greatly increased my run time, but my accuracy jumped up.\n",
    "\n",
    "I set param_dist with a range of n_estimators, and a range of max_depths. Start a new RandomForestClassifier as rf instance. Then I run rf through RandomizedSearchCV, using the param_dist setting I stated earlier. I also state the number of trees I want to create, n_iter=10, and cv=5 (the number of cross-validation folds to use). And save this result in the variable rand_search.\n",
    "\n",
    "Next, I fit(X, y) in rand_search. Next, I run rand_search, find the tree that performed the best with the given data, and save it in best_rf.\n",
    "\n",
    "I am printing to console the best parameters that RandomizedSearchCV has found as a reference.\n",
    "Using best_rf, I make my predictions and store them in answers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d25ce910-a051-4467-9585-ef0f1fee95cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyperparameters: {'max_depth': 6, 'n_estimators': 330}\n"
     ]
    }
   ],
   "source": [
    "param_dist = {'n_estimators': randint(100,375),\n",
    "              'max_depth': randint(5,20)}\n",
    "\n",
    "rf = RandomForestClassifier()\n",
    "\n",
    "rand_search = RandomizedSearchCV(rf, param_distributions = param_dist, n_iter=10, cv=5)\n",
    "\n",
    "rand_search.fit(X, y)\n",
    "\n",
    "best_rf = rand_search.best_estimator_\n",
    "\n",
    "print('Best hyperparameters:',  rand_search.best_params_)\n",
    "\n",
    "answers = best_rf.predict(test_table[all_covariates])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1737b17-c1fd-491d-a95c-c088913156f3",
   "metadata": {},
   "source": [
    "Using my list of answers, I create a table that mimics the initial df_test_labels, with the answers included, and save that table to test_labels.csv.\n",
    "\n",
    "End my runtime counter, disply the runtime result to the console."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "db30ff7e-52c8-445a-9adb-d3fc4b2163c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run time: 42.696559 s.ms\n"
     ]
    }
   ],
   "source": [
    "results = []\n",
    "for i in range(len(answers)):\n",
    "    results.append([\n",
    "        df_test_labels.orig_index.iloc[i],\n",
    "        df_test_labels.timestamp.iloc[i],\n",
    "        df_test_labels['UTC time'].iloc[i],\n",
    "        answers[i]\n",
    "    ])\n",
    "\n",
    "results = pd.DataFrame(results, columns=['', 'timestamp', 'UTC time', 'label'])\n",
    "\n",
    "results.to_csv(os.path.join(data_dir, \"test_labels.csv\"), sep=\",\", index=False)\n",
    "\n",
    "end_time = datetime.datetime.now()\n",
    "\n",
    "# print elasped time to console\n",
    "print(\"Run time: \" + str(end_time - start_time)[5:] + \" s.ms\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bdfabdf-18a8-42fe-a82c-4342fd321d28",
   "metadata": {},
   "source": [
    "Manipulating the n_iter changes the number of trees created for comparison. The higher this number goes, the better the accuracy, and the higher the runtime. I chose n_iter=10 because it improves the accuracy, and keeps my runtime below 1 minute."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
